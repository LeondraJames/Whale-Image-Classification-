{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-atf3gekcgR"
   },
   "source": [
    "# Assessment 1: I can train and deploy a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wkT17FkmU6"
   },
   "source": [
    "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
    "\n",
    "We've included a dataset which consists of two classes:  \n",
    "\n",
    "1) Face: Contains images which include the face of a whale  \n",
    "2) Not Face: Contains images which do not include the face of a whale.  \n",
    "\n",
    "The dataset is located at ```/dli/data/whale/data/train```.\n",
    "\n",
    "Your challenge is:\n",
    "\n",
    "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
    "\n",
    "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
    "\n",
    "Resources:\n",
    "\n",
    "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
    "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
    "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
    "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaaY1Vb3o3mC"
   },
   "source": [
    "Start in [DIGITS](/digits/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log\t      snapshot_iter_270.caffemodel\r\n",
      "deploy.prototxt\t\t      snapshot_iter_270.solverstate\r\n",
      "original.prototxt\t      snapshot_iter_54.caffemodel\r\n",
      "snapshot_iter_108.caffemodel  solver.prototxt\r\n",
      "snapshot_iter_162.caffemodel  status.pickle\r\n",
      "snapshot_iter_216.caffemodel  train_val.prototxt\r\n"
     ]
    }
   ],
   "source": [
    "#Load modules & set objects for dataset and model\n",
    "import caffe\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "MODEL_JOB_DIR = '/dli/data/digits/20190926-221500-abfc'  ## Set this to be the job number for your model\n",
    "DATASET_JOB_DIR = '/dli/data/digits/20190926-220654-3c91'  ## Set this to be the job number for your dataset\n",
    "\n",
    "!ls $MODEL_JOB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_train_db.log  labels.txt        mean.jpg       train.txt  val.txt\r\n",
      "create_val_db.log    mean.binaryproto  status.pickle  train_db\t val_db\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATASET_JOB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE = MODEL_JOB_DIR + '/deploy.prototxt'                 # Do not change\n",
    "WEIGHTS = MODEL_JOB_DIR + '/snapshot_iter_270.caffemodel'    # Do not change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not whale\n"
     ]
    }
   ],
   "source": [
    "#Build model\n",
    "def deploy(img_path):\n",
    "\n",
    "    caffe.set_mode_gpu()\n",
    "    \n",
    "    # Initialize the Caffe model using the model trained in DIGITS. Which two files constitute your trained model?\n",
    "    net = caffe.Classifier(ARCHITECTURE, WEIGHTS,\n",
    "                           channel_swap=(2,1,0),\n",
    "                           raw_scale=255,\n",
    "                           image_dims=(256, 256)) \n",
    "    \n",
    "    # Create an input that the network expects. \n",
    "    input_image = caffe.io.load_image(DATASET_JOB_DIR+'/mean.jpg')\n",
    "    input_image = cv2.resize(input_image, (256,256))\n",
    "    mean_image = caffe.io.load_image('/dli/data/digits/20190926-220654-3c91/mean.jpg')\n",
    "    ready_image = input_image-mean_image\n",
    "    \n",
    "#spot for viz\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = net.predict([ready_image])\n",
    "\n",
    "    # Create an output that is useful to a user. What is the condition that should return \"whale\" vs. \"not whale\"?\n",
    "    if prediction.argmax() == 0:\n",
    "        return \"whale\"\n",
    "    else:\n",
    "        return \"not whale\"\n",
    "    \n",
    "#Ignore this part    \n",
    "if __name__ == \"__main__\":\n",
    "    print(deploy(sys.argv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0926 23:29:45.952100   317 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0926 23:29:45.952787   317 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11608981504, dev_info[0]: total=11996954624 free=11608981504\n",
      "W0926 23:29:45.952837   317 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0926 23:29:45.952983   317 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0926 23:29:45.953001   317 _caffe.cpp:175] Net('/dli/data/digits/20190926-221500-abfc/deploy.prototxt', 1, weights='/dli/data/digits/20190926-221500-abfc/snapshot_iter_270.caffemodel')\n",
      "I0926 23:29:45.953294   317 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190926-221500-abfc/deploy.prototxt\n",
      "I0926 23:29:45.953320   317 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0926 23:29:45.953330   317 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0926 23:29:45.962707   317 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0926 23:29:45.963094   317 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0926 23:29:45.963110   317 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0926 23:29:45.963125   317 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0926 23:29:45.963137   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:45.963157   317 net.cpp:199] Created Layer input (0)\n",
      "I0926 23:29:45.963171   317 net.cpp:541] input -> data\n",
      "I0926 23:29:45.963790   317 net.cpp:259] Setting up input\n",
      "I0926 23:29:45.963815   317 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0926 23:29:45.963826   317 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0926 23:29:45.963838   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:45.963869   317 net.cpp:199] Created Layer conv1 (1)\n",
      "I0926 23:29:45.963881   317 net.cpp:571] conv1 <- data\n",
      "I0926 23:29:45.963894   317 net.cpp:541] conv1 -> conv1\n",
      "I0926 23:29:46.482587   317 net.cpp:259] Setting up conv1\n",
      "I0926 23:29:46.482633   317 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0926 23:29:46.482656   317 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0926 23:29:46.482674   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.482688   317 net.cpp:199] Created Layer relu1 (2)\n",
      "I0926 23:29:46.482700   317 net.cpp:571] relu1 <- conv1\n",
      "I0926 23:29:46.482708   317 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0926 23:29:46.482734   317 net.cpp:259] Setting up relu1\n",
      "I0926 23:29:46.482748   317 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0926 23:29:46.482760   317 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0926 23:29:46.482771   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.482801   317 net.cpp:199] Created Layer norm1 (3)\n",
      "I0926 23:29:46.482811   317 net.cpp:571] norm1 <- conv1\n",
      "I0926 23:29:46.482828   317 net.cpp:541] norm1 -> norm1\n",
      "I0926 23:29:46.482887   317 net.cpp:259] Setting up norm1\n",
      "I0926 23:29:46.482903   317 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0926 23:29:46.482910   317 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0926 23:29:46.482923   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.482965   317 net.cpp:199] Created Layer pool1 (4)\n",
      "I0926 23:29:46.482975   317 net.cpp:571] pool1 <- norm1\n",
      "I0926 23:29:46.482986   317 net.cpp:541] pool1 -> pool1\n",
      "I0926 23:29:46.483048   317 net.cpp:259] Setting up pool1\n",
      "I0926 23:29:46.483063   317 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0926 23:29:46.483078   317 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0926 23:29:46.483086   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.483105   317 net.cpp:199] Created Layer conv2 (5)\n",
      "I0926 23:29:46.483115   317 net.cpp:571] conv2 <- pool1\n",
      "I0926 23:29:46.483124   317 net.cpp:541] conv2 -> conv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0926 23:29:46.490167   317 net.cpp:259] Setting up conv2\n",
      "I0926 23:29:46.490200   317 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0926 23:29:46.490228   317 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0926 23:29:46.490247   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.490267   317 net.cpp:199] Created Layer relu2 (6)\n",
      "I0926 23:29:46.490283   317 net.cpp:571] relu2 <- conv2\n",
      "I0926 23:29:46.490299   317 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0926 23:29:46.490321   317 net.cpp:259] Setting up relu2\n",
      "I0926 23:29:46.490339   317 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0926 23:29:46.490358   317 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0926 23:29:46.490375   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.490401   317 net.cpp:199] Created Layer norm2 (7)\n",
      "I0926 23:29:46.490418   317 net.cpp:571] norm2 <- conv2\n",
      "I0926 23:29:46.490434   317 net.cpp:541] norm2 -> norm2\n",
      "I0926 23:29:46.490519   317 net.cpp:259] Setting up norm2\n",
      "I0926 23:29:46.490543   317 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0926 23:29:46.490563   317 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0926 23:29:46.490581   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.490604   317 net.cpp:199] Created Layer pool2 (8)\n",
      "I0926 23:29:46.490620   317 net.cpp:571] pool2 <- norm2\n",
      "I0926 23:29:46.490638   317 net.cpp:541] pool2 -> pool2\n",
      "I0926 23:29:46.490732   317 net.cpp:259] Setting up pool2\n",
      "I0926 23:29:46.490757   317 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0926 23:29:46.490779   317 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0926 23:29:46.490798   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.490826   317 net.cpp:199] Created Layer conv3 (9)\n",
      "I0926 23:29:46.490844   317 net.cpp:571] conv3 <- pool2\n",
      "I0926 23:29:46.490864   317 net.cpp:541] conv3 -> conv3\n",
      "I0926 23:29:46.506462   317 net.cpp:259] Setting up conv3\n",
      "I0926 23:29:46.506486   317 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0926 23:29:46.506502   317 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0926 23:29:46.506515   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.506523   317 net.cpp:199] Created Layer relu3 (10)\n",
      "I0926 23:29:46.506531   317 net.cpp:571] relu3 <- conv3\n",
      "I0926 23:29:46.506539   317 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0926 23:29:46.506554   317 net.cpp:259] Setting up relu3\n",
      "I0926 23:29:46.506562   317 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0926 23:29:46.506574   317 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0926 23:29:46.506580   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.506599   317 net.cpp:199] Created Layer conv4 (11)\n",
      "I0926 23:29:46.506609   317 net.cpp:571] conv4 <- conv3\n",
      "I0926 23:29:46.506615   317 net.cpp:541] conv4 -> conv4\n",
      "I0926 23:29:46.518803   317 net.cpp:259] Setting up conv4\n",
      "I0926 23:29:46.518831   317 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0926 23:29:46.518867   317 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0926 23:29:46.518875   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.518885   317 net.cpp:199] Created Layer relu4 (12)\n",
      "I0926 23:29:46.518898   317 net.cpp:571] relu4 <- conv4\n",
      "I0926 23:29:46.518905   317 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0926 23:29:46.518918   317 net.cpp:259] Setting up relu4\n",
      "I0926 23:29:46.518927   317 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0926 23:29:46.518939   317 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0926 23:29:46.518945   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.518963   317 net.cpp:199] Created Layer conv5 (13)\n",
      "I0926 23:29:46.518975   317 net.cpp:571] conv5 <- conv4\n",
      "I0926 23:29:46.518981   317 net.cpp:541] conv5 -> conv5\n",
      "I0926 23:29:46.526921   317 net.cpp:259] Setting up conv5\n",
      "I0926 23:29:46.526944   317 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0926 23:29:46.526962   317 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0926 23:29:46.526974   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.526983   317 net.cpp:199] Created Layer relu5 (14)\n",
      "I0926 23:29:46.526989   317 net.cpp:571] relu5 <- conv5\n",
      "I0926 23:29:46.526998   317 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0926 23:29:46.527012   317 net.cpp:259] Setting up relu5\n",
      "I0926 23:29:46.527021   317 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0926 23:29:46.527032   317 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0926 23:29:46.527038   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.527053   317 net.cpp:199] Created Layer pool5 (15)\n",
      "I0926 23:29:46.527065   317 net.cpp:571] pool5 <- conv5\n",
      "I0926 23:29:46.527070   317 net.cpp:541] pool5 -> pool5\n",
      "I0926 23:29:46.527132   317 net.cpp:259] Setting up pool5\n",
      "I0926 23:29:46.527148   317 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0926 23:29:46.527155   317 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0926 23:29:46.527166   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:46.527177   317 net.cpp:199] Created Layer fc6 (16)\n",
      "I0926 23:29:46.527189   317 net.cpp:571] fc6 <- pool5\n",
      "I0926 23:29:46.527195   317 net.cpp:541] fc6 -> fc6\n",
      "I0926 23:29:47.201289   317 net.cpp:259] Setting up fc6\n",
      "I0926 23:29:47.201334   317 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0926 23:29:47.201359   317 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0926 23:29:47.201372   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.201390   317 net.cpp:199] Created Layer relu6 (17)\n",
      "I0926 23:29:47.201401   317 net.cpp:571] relu6 <- fc6\n",
      "I0926 23:29:47.201416   317 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0926 23:29:47.201436   317 net.cpp:259] Setting up relu6\n",
      "I0926 23:29:47.201447   317 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0926 23:29:47.201457   317 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0926 23:29:47.201469   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.201486   317 net.cpp:199] Created Layer drop6 (18)\n",
      "I0926 23:29:47.201496   317 net.cpp:571] drop6 <- fc6\n",
      "I0926 23:29:47.201508   317 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0926 23:29:47.235906   317 net.cpp:259] Setting up drop6\n",
      "I0926 23:29:47.235935   317 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0926 23:29:47.235947   317 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0926 23:29:47.235958   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.235972   317 net.cpp:199] Created Layer fc7 (19)\n",
      "I0926 23:29:47.236011   317 net.cpp:571] fc7 <- fc6\n",
      "I0926 23:29:47.236025   317 net.cpp:541] fc7 -> fc7\n",
      "I0926 23:29:47.536911   317 net.cpp:259] Setting up fc7\n",
      "I0926 23:29:47.536967   317 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0926 23:29:47.536989   317 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0926 23:29:47.537001   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.537014   317 net.cpp:199] Created Layer relu7 (20)\n",
      "I0926 23:29:47.537024   317 net.cpp:571] relu7 <- fc7\n",
      "I0926 23:29:47.537037   317 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0926 23:29:47.537057   317 net.cpp:259] Setting up relu7\n",
      "I0926 23:29:47.537068   317 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0926 23:29:47.537081   317 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0926 23:29:47.537091   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.537109   317 net.cpp:199] Created Layer drop7 (21)\n",
      "I0926 23:29:47.537119   317 net.cpp:571] drop7 <- fc7\n",
      "I0926 23:29:47.537130   317 net.cpp:526] drop7 -> fc7 (in-place)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0926 23:29:47.571631   317 net.cpp:259] Setting up drop7\n",
      "I0926 23:29:47.571664   317 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0926 23:29:47.571686   317 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0926 23:29:47.571707   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.571729   317 net.cpp:199] Created Layer fc8 (22)\n",
      "I0926 23:29:47.571748   317 net.cpp:571] fc8 <- fc7\n",
      "I0926 23:29:47.571768   317 net.cpp:541] fc8 -> fc8\n",
      "I0926 23:29:47.572757   317 net.cpp:259] Setting up fc8\n",
      "I0926 23:29:47.572783   317 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0926 23:29:47.572799   317 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0926 23:29:47.572811   317 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:47.572830   317 net.cpp:199] Created Layer softmax (23)\n",
      "I0926 23:29:47.572844   317 net.cpp:571] softmax <- fc8\n",
      "I0926 23:29:47.572851   317 net.cpp:541] softmax -> softmax\n",
      "I0926 23:29:47.572934   317 net.cpp:259] Setting up softmax\n",
      "I0926 23:29:47.572973   317 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0926 23:29:47.572984   317 net.cpp:337] softmax does not need backward computation.\n",
      "I0926 23:29:47.572991   317 net.cpp:337] fc8 does not need backward computation.\n",
      "I0926 23:29:47.573001   317 net.cpp:337] drop7 does not need backward computation.\n",
      "I0926 23:29:47.573007   317 net.cpp:337] relu7 does not need backward computation.\n",
      "I0926 23:29:47.573017   317 net.cpp:337] fc7 does not need backward computation.\n",
      "I0926 23:29:47.573022   317 net.cpp:337] drop6 does not need backward computation.\n",
      "I0926 23:29:47.573027   317 net.cpp:337] relu6 does not need backward computation.\n",
      "I0926 23:29:47.573034   317 net.cpp:337] fc6 does not need backward computation.\n",
      "I0926 23:29:47.573043   317 net.cpp:337] pool5 does not need backward computation.\n",
      "I0926 23:29:47.573053   317 net.cpp:337] relu5 does not need backward computation.\n",
      "I0926 23:29:47.573062   317 net.cpp:337] conv5 does not need backward computation.\n",
      "I0926 23:29:47.573073   317 net.cpp:337] relu4 does not need backward computation.\n",
      "I0926 23:29:47.573082   317 net.cpp:337] conv4 does not need backward computation.\n",
      "I0926 23:29:47.573091   317 net.cpp:337] relu3 does not need backward computation.\n",
      "I0926 23:29:47.573101   317 net.cpp:337] conv3 does not need backward computation.\n",
      "I0926 23:29:47.573112   317 net.cpp:337] pool2 does not need backward computation.\n",
      "I0926 23:29:47.573122   317 net.cpp:337] norm2 does not need backward computation.\n",
      "I0926 23:29:47.573133   317 net.cpp:337] relu2 does not need backward computation.\n",
      "I0926 23:29:47.573143   317 net.cpp:337] conv2 does not need backward computation.\n",
      "I0926 23:29:47.573153   317 net.cpp:337] pool1 does not need backward computation.\n",
      "I0926 23:29:47.573187   317 net.cpp:337] norm1 does not need backward computation.\n",
      "I0926 23:29:47.573199   317 net.cpp:337] relu1 does not need backward computation.\n",
      "I0926 23:29:47.573204   317 net.cpp:337] conv1 does not need backward computation.\n",
      "I0926 23:29:47.573216   317 net.cpp:337] input does not need backward computation.\n",
      "I0926 23:29:47.573221   317 net.cpp:379] This network produces output softmax\n",
      "I0926 23:29:47.573248   317 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0926 23:29:47.573259   317 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0926 23:29:47.573266   317 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0926 23:29:47.573276   317 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0926 23:29:47.573280   317 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0926 23:29:47.573290   317 net.cpp:420] Network initialization done.\n",
      "I0926 23:29:47.676883   317 net.cpp:1129] Ignoring source layer train-data\n",
      "I0926 23:29:47.676919   317 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0926 23:29:47.677026   317 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.677042   317 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0926 23:29:47.677048   317 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0926 23:29:47.677059   317 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0926 23:29:47.677219   317 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.677232   317 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0926 23:29:47.677239   317 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0926 23:29:47.677251   317 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0926 23:29:47.677670   317 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.677685   317 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0926 23:29:47.678006   317 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.678020   317 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0926 23:29:47.678232   317 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.678246   317 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0926 23:29:47.678252   317 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0926 23:29:47.694563   317 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.694593   317 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0926 23:29:47.694599   317 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0926 23:29:47.701874   317 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0926 23:29:47.701900   317 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0926 23:29:47.701912   317 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0926 23:29:47.701941   317 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n",
      "I0926 23:29:49.481812   329 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0926 23:29:49.482545   329 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11608981504, dev_info[0]: total=11996954624 free=11608981504\n",
      "W0926 23:29:49.482606   329 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0926 23:29:49.482733   329 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0926 23:29:49.482748   329 _caffe.cpp:175] Net('/dli/data/digits/20190926-221500-abfc/deploy.prototxt', 1, weights='/dli/data/digits/20190926-221500-abfc/snapshot_iter_270.caffemodel')\n",
      "I0926 23:29:49.483058   329 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190926-221500-abfc/deploy.prototxt\n",
      "I0926 23:29:49.483091   329 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0926 23:29:49.483108   329 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0926 23:29:49.492491   329 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0926 23:29:49.492959   329 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0926 23:29:49.492974   329 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0926 23:29:49.492988   329 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0926 23:29:49.493000   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:49.493021   329 net.cpp:199] Created Layer input (0)\n",
      "I0926 23:29:49.493036   329 net.cpp:541] input -> data\n",
      "I0926 23:29:49.493675   329 net.cpp:259] Setting up input\n",
      "I0926 23:29:49.493700   329 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0926 23:29:49.493716   329 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0926 23:29:49.493727   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:49.493757   329 net.cpp:199] Created Layer conv1 (1)\n",
      "I0926 23:29:49.493769   329 net.cpp:571] conv1 <- data\n",
      "I0926 23:29:49.493782   329 net.cpp:541] conv1 -> conv1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0926 23:29:50.011591   329 net.cpp:259] Setting up conv1\n",
      "I0926 23:29:50.011643   329 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0926 23:29:50.011678   329 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0926 23:29:50.011696   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.011715   329 net.cpp:199] Created Layer relu1 (2)\n",
      "I0926 23:29:50.011727   329 net.cpp:571] relu1 <- conv1\n",
      "I0926 23:29:50.011740   329 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0926 23:29:50.011765   329 net.cpp:259] Setting up relu1\n",
      "I0926 23:29:50.011778   329 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0926 23:29:50.011790   329 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0926 23:29:50.011801   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.011831   329 net.cpp:199] Created Layer norm1 (3)\n",
      "I0926 23:29:50.011840   329 net.cpp:571] norm1 <- conv1\n",
      "I0926 23:29:50.011852   329 net.cpp:541] norm1 -> norm1\n",
      "I0926 23:29:50.011914   329 net.cpp:259] Setting up norm1\n",
      "I0926 23:29:50.011930   329 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0926 23:29:50.011942   329 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0926 23:29:50.011953   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.011994   329 net.cpp:199] Created Layer pool1 (4)\n",
      "I0926 23:29:50.012007   329 net.cpp:571] pool1 <- norm1\n",
      "I0926 23:29:50.012013   329 net.cpp:541] pool1 -> pool1\n",
      "I0926 23:29:50.012074   329 net.cpp:259] Setting up pool1\n",
      "I0926 23:29:50.012089   329 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0926 23:29:50.012101   329 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0926 23:29:50.012114   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.012135   329 net.cpp:199] Created Layer conv2 (5)\n",
      "I0926 23:29:50.012145   329 net.cpp:571] conv2 <- pool1\n",
      "I0926 23:29:50.012157   329 net.cpp:541] conv2 -> conv2\n",
      "I0926 23:29:50.019160   329 net.cpp:259] Setting up conv2\n",
      "I0926 23:29:50.019188   329 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0926 23:29:50.019212   329 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0926 23:29:50.019225   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.019245   329 net.cpp:199] Created Layer relu2 (6)\n",
      "I0926 23:29:50.019258   329 net.cpp:571] relu2 <- conv2\n",
      "I0926 23:29:50.019269   329 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0926 23:29:50.019291   329 net.cpp:259] Setting up relu2\n",
      "I0926 23:29:50.019309   329 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0926 23:29:50.019321   329 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0926 23:29:50.019336   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.019356   329 net.cpp:199] Created Layer norm2 (7)\n",
      "I0926 23:29:50.019371   329 net.cpp:571] norm2 <- conv2\n",
      "I0926 23:29:50.019387   329 net.cpp:541] norm2 -> norm2\n",
      "I0926 23:29:50.019441   329 net.cpp:259] Setting up norm2\n",
      "I0926 23:29:50.019457   329 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0926 23:29:50.019464   329 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0926 23:29:50.019472   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.019484   329 net.cpp:199] Created Layer pool2 (8)\n",
      "I0926 23:29:50.019496   329 net.cpp:571] pool2 <- norm2\n",
      "I0926 23:29:50.019503   329 net.cpp:541] pool2 -> pool2\n",
      "I0926 23:29:50.019554   329 net.cpp:259] Setting up pool2\n",
      "I0926 23:29:50.019569   329 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0926 23:29:50.019578   329 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0926 23:29:50.019589   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.019604   329 net.cpp:199] Created Layer conv3 (9)\n",
      "I0926 23:29:50.019614   329 net.cpp:571] conv3 <- pool2\n",
      "I0926 23:29:50.019623   329 net.cpp:541] conv3 -> conv3\n",
      "I0926 23:29:50.035254   329 net.cpp:259] Setting up conv3\n",
      "I0926 23:29:50.035279   329 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0926 23:29:50.035302   329 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0926 23:29:50.035316   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.035336   329 net.cpp:199] Created Layer relu3 (10)\n",
      "I0926 23:29:50.035347   329 net.cpp:571] relu3 <- conv3\n",
      "I0926 23:29:50.035358   329 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0926 23:29:50.035379   329 net.cpp:259] Setting up relu3\n",
      "I0926 23:29:50.035398   329 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0926 23:29:50.035409   329 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0926 23:29:50.035424   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.035449   329 net.cpp:199] Created Layer conv4 (11)\n",
      "I0926 23:29:50.035461   329 net.cpp:571] conv4 <- conv3\n",
      "I0926 23:29:50.035478   329 net.cpp:541] conv4 -> conv4\n",
      "I0926 23:29:50.047886   329 net.cpp:259] Setting up conv4\n",
      "I0926 23:29:50.047912   329 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0926 23:29:50.047950   329 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0926 23:29:50.047960   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.047973   329 net.cpp:199] Created Layer relu4 (12)\n",
      "I0926 23:29:50.047986   329 net.cpp:571] relu4 <- conv4\n",
      "I0926 23:29:50.047993   329 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0926 23:29:50.048007   329 net.cpp:259] Setting up relu4\n",
      "I0926 23:29:50.048019   329 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0926 23:29:50.048028   329 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0926 23:29:50.048039   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.048058   329 net.cpp:199] Created Layer conv5 (13)\n",
      "I0926 23:29:50.048069   329 net.cpp:571] conv5 <- conv4\n",
      "I0926 23:29:50.048076   329 net.cpp:541] conv5 -> conv5\n",
      "I0926 23:29:50.056093   329 net.cpp:259] Setting up conv5\n",
      "I0926 23:29:50.056118   329 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0926 23:29:50.056141   329 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0926 23:29:50.056161   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.056182   329 net.cpp:199] Created Layer relu5 (14)\n",
      "I0926 23:29:50.056195   329 net.cpp:571] relu5 <- conv5\n",
      "I0926 23:29:50.056202   329 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0926 23:29:50.056217   329 net.cpp:259] Setting up relu5\n",
      "I0926 23:29:50.056229   329 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0926 23:29:50.056237   329 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0926 23:29:50.056249   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.056270   329 net.cpp:199] Created Layer pool5 (15)\n",
      "I0926 23:29:50.056286   329 net.cpp:571] pool5 <- conv5\n",
      "I0926 23:29:50.056298   329 net.cpp:541] pool5 -> pool5\n",
      "I0926 23:29:50.056377   329 net.cpp:259] Setting up pool5\n",
      "I0926 23:29:50.056397   329 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0926 23:29:50.056409   329 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0926 23:29:50.056421   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.056450   329 net.cpp:199] Created Layer fc6 (16)\n",
      "I0926 23:29:50.056465   329 net.cpp:571] fc6 <- pool5\n",
      "I0926 23:29:50.056478   329 net.cpp:541] fc6 -> fc6\n",
      "I0926 23:29:50.727324   329 net.cpp:259] Setting up fc6\n",
      "I0926 23:29:50.727373   329 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0926 23:29:50.727403   329 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0926 23:29:50.727419   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.727432   329 net.cpp:199] Created Layer relu6 (17)\n",
      "I0926 23:29:50.727443   329 net.cpp:571] relu6 <- fc6\n",
      "I0926 23:29:50.727454   329 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0926 23:29:50.727473   329 net.cpp:259] Setting up relu6\n",
      "I0926 23:29:50.727484   329 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0926 23:29:50.727491   329 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0926 23:29:50.727502   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.727519   329 net.cpp:199] Created Layer drop6 (18)\n",
      "I0926 23:29:50.727530   329 net.cpp:571] drop6 <- fc6\n",
      "I0926 23:29:50.727536   329 net.cpp:526] drop6 -> fc6 (in-place)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0926 23:29:50.761958   329 net.cpp:259] Setting up drop6\n",
      "I0926 23:29:50.761983   329 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0926 23:29:50.761998   329 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0926 23:29:50.762015   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:50.762033   329 net.cpp:199] Created Layer fc7 (19)\n",
      "I0926 23:29:50.762073   329 net.cpp:571] fc7 <- fc6\n",
      "I0926 23:29:50.762090   329 net.cpp:541] fc7 -> fc7\n",
      "I0926 23:29:51.061684   329 net.cpp:259] Setting up fc7\n",
      "I0926 23:29:51.061734   329 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0926 23:29:51.061764   329 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0926 23:29:51.061782   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:51.061805   329 net.cpp:199] Created Layer relu7 (20)\n",
      "I0926 23:29:51.061820   329 net.cpp:571] relu7 <- fc7\n",
      "I0926 23:29:51.061839   329 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0926 23:29:51.061863   329 net.cpp:259] Setting up relu7\n",
      "I0926 23:29:51.061877   329 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0926 23:29:51.061894   329 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0926 23:29:51.061910   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:51.061935   329 net.cpp:199] Created Layer drop7 (21)\n",
      "I0926 23:29:51.061949   329 net.cpp:571] drop7 <- fc7\n",
      "I0926 23:29:51.061966   329 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0926 23:29:51.096531   329 net.cpp:259] Setting up drop7\n",
      "I0926 23:29:51.096561   329 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0926 23:29:51.096582   329 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0926 23:29:51.096596   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:51.096611   329 net.cpp:199] Created Layer fc8 (22)\n",
      "I0926 23:29:51.096623   329 net.cpp:571] fc8 <- fc7\n",
      "I0926 23:29:51.096632   329 net.cpp:541] fc8 -> fc8\n",
      "I0926 23:29:51.097576   329 net.cpp:259] Setting up fc8\n",
      "I0926 23:29:51.097600   329 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0926 23:29:51.097623   329 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0926 23:29:51.097641   329 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0926 23:29:51.097671   329 net.cpp:199] Created Layer softmax (23)\n",
      "I0926 23:29:51.097685   329 net.cpp:571] softmax <- fc8\n",
      "I0926 23:29:51.097702   329 net.cpp:541] softmax -> softmax\n",
      "I0926 23:29:51.097790   329 net.cpp:259] Setting up softmax\n",
      "I0926 23:29:51.097810   329 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0926 23:29:51.097826   329 net.cpp:337] softmax does not need backward computation.\n",
      "I0926 23:29:51.097841   329 net.cpp:337] fc8 does not need backward computation.\n",
      "I0926 23:29:51.097856   329 net.cpp:337] drop7 does not need backward computation.\n",
      "I0926 23:29:51.097870   329 net.cpp:337] relu7 does not need backward computation.\n",
      "I0926 23:29:51.097885   329 net.cpp:337] fc7 does not need backward computation.\n",
      "I0926 23:29:51.097900   329 net.cpp:337] drop6 does not need backward computation.\n",
      "I0926 23:29:51.097914   329 net.cpp:337] relu6 does not need backward computation.\n",
      "I0926 23:29:51.097929   329 net.cpp:337] fc6 does not need backward computation.\n",
      "I0926 23:29:51.097944   329 net.cpp:337] pool5 does not need backward computation.\n",
      "I0926 23:29:51.097959   329 net.cpp:337] relu5 does not need backward computation.\n",
      "I0926 23:29:51.097973   329 net.cpp:337] conv5 does not need backward computation.\n",
      "I0926 23:29:51.097988   329 net.cpp:337] relu4 does not need backward computation.\n",
      "I0926 23:29:51.098002   329 net.cpp:337] conv4 does not need backward computation.\n",
      "I0926 23:29:51.098017   329 net.cpp:337] relu3 does not need backward computation.\n",
      "I0926 23:29:51.098031   329 net.cpp:337] conv3 does not need backward computation.\n",
      "I0926 23:29:51.098047   329 net.cpp:337] pool2 does not need backward computation.\n",
      "I0926 23:29:51.098062   329 net.cpp:337] norm2 does not need backward computation.\n",
      "I0926 23:29:51.098076   329 net.cpp:337] relu2 does not need backward computation.\n",
      "I0926 23:29:51.098090   329 net.cpp:337] conv2 does not need backward computation.\n",
      "I0926 23:29:51.098106   329 net.cpp:337] pool1 does not need backward computation.\n",
      "I0926 23:29:51.098146   329 net.cpp:337] norm1 does not need backward computation.\n",
      "I0926 23:29:51.098161   329 net.cpp:337] relu1 does not need backward computation.\n",
      "I0926 23:29:51.098176   329 net.cpp:337] conv1 does not need backward computation.\n",
      "I0926 23:29:51.098192   329 net.cpp:337] input does not need backward computation.\n",
      "I0926 23:29:51.098206   329 net.cpp:379] This network produces output softmax\n",
      "I0926 23:29:51.098242   329 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0926 23:29:51.098256   329 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0926 23:29:51.098273   329 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0926 23:29:51.098286   329 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0926 23:29:51.098300   329 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0926 23:29:51.098315   329 net.cpp:420] Network initialization done.\n",
      "I0926 23:29:51.202118   329 net.cpp:1129] Ignoring source layer train-data\n",
      "I0926 23:29:51.202154   329 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0926 23:29:51.202246   329 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.202261   329 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0926 23:29:51.202272   329 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0926 23:29:51.202277   329 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0926 23:29:51.202437   329 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.202450   329 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0926 23:29:51.202462   329 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0926 23:29:51.202479   329 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0926 23:29:51.202895   329 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.202910   329 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0926 23:29:51.203225   329 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.203240   329 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0926 23:29:51.203461   329 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.203476   329 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0926 23:29:51.203486   329 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0926 23:29:51.219777   329 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.219813   329 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0926 23:29:51.219830   329 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0926 23:29:51.227383   329 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0926 23:29:51.227412   329 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0926 23:29:51.227418   329 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0926 23:29:51.227459   329 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom\n",
    "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Assessment1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
